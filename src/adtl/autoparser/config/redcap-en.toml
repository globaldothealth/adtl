
name = "redcap-en"
description = "Autoparser config for generating CSV mappings and TOML from REDCap dictionaries"

# Used by parse_choices() to generate values mapping
# Using the delimiters below, we can parse this:
#   1, yes | 2, always | 3, sometimes
# to this TOML:
#  { 1 = "yes", 2 = "always", 3 = "sometimes" }

choice_delimiter = "|"
choice_delimiter_map = ","

# max number of references to use in the parser file
num_refs = 3

# maximum number of unique values a column can contain for them to be considered 'common'
# and which might need to be mapped in the parser. e.g. a column with only
# 'oui, non, inconnu' as unique values would be considered to have common values,
# while a column with 50 unique values (perhaps because they are dates, or IDs) would not.
# Maximum is 30% of the dataset length (relevant for small datasets to limit data leakage).
max_common_count = 25

# Optional:
# Frequency required for a value to be considered common. Max_common_count will act on
# the filtered 'common' list of values.
# Will default to 5% if the max_common_count is > 30% of the dataset.
# min_common_freq = 0.002

# Path to the target schemas, one per table
[schemas]
  linelist = "schemas/linelist.schema.json"

# Column mappings to standardise column names across data dictionaries
[column_mappings]
  source_field = "Variable / Field Name"
  source_type = "Field Type"
  source_description = "Field Label"
  choices = "Choices, Calculations, OR Slider Labels"

# Optional: long tables configuration
# [long_tables.attribute]
# id_cols = ["subjid", "dataset_id"]
# variable_col = "attribute"
# value_cols = ["value_bool", "value_num", "value"]

# [long_tables.event]
# id_cols = ["subjid", "dataset_id"]
# variable_col = "attribute"
# value_cols = ["value_bool", "value_num", "value"]
